OPENAI_API_KEY="your-openai-api-key-here"
OPENAI_MODEL="gpt-5-mini"
LANGSMITH_API_KEY="your-langsmith-api-key-here"
LANGSMITH_PROJECT="log-analyzer"
USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/124.0.0.0"
LOG_DIRECTORY="./logs"

# Throttle delay between evaluation examples (seconds).
# Increase if hitting provider rate limits (e.g. Gemini free tier = 5 RPM, use 15+).
# Set to 0 to disable throttling (paid tiers with high RPM limits).
EVAL_THROTTLE_SECONDS=15

# LLM-as-judge. Should be a DIFFERENT provider/model from your agent
# to avoid self-preference bias (e.g. agent=groq/llama, judge=openai/gpt-4o-mini).
JUDGE_PROVIDER=openai
JUDGE_MODEL=gpt-4o-mini